
@article{steinwart_influence_2002,
	title = {On the influence of the kernel on the consistency of support vector machines},
	volume = {2},
	issn = {1532-4435},
	url = {https://dl.acm.org/doi/10.1162/153244302760185252},
	doi = {10.1162/153244302760185252},
	abstract = {In this article we study the generalization abilities of several classifiers of support vector machine (SVM) type using a certain class of kernels that we call universal. It is shown that the soft margin algorithms with universal kernels are consistent for a large class of classification problems including some kind of noisy tasks provided that the regularization parameter is chosen well. In particular we derive a simple sufficient condition for this parameter in the case of Gaussian RBF kernels. On the one hand our considerations are based on an investigation of an approximation property---the so-called universality---of the used kernels that ensures that all continuous functions can be approximated by certain kernel expressions. This approximation property also gives a new insight into the role of kernels in these and other algorithms. On the other hand the results are achieved by a precise study of the underlying optimization problems of the classifiers. Furthermore, we show consistency for the maximal margin classifier as well as for the soft margin SVM's in the presence of large margins. In this case it turns out that also constant regularization parameters ensure consistency for the soft margin SVM's. Finally we prove that even for simple, noise free classification problems SVM's with polynomial kernels can behave arbitrarily badly.},
	urldate = {2024-06-12},
	journal = {The Journal of Machine Learning Research},
	author = {Steinwart, Ingo},
	month = mar,
	year = {2002},
	keywords = {computational learning theory, kernel methods, PAC model, pattern recognition, support vector machines},
	pages = {67--93},
	file = {Full Text PDF:C\:\\Users\\Andre\\Zotero\\storage\\W8KTD9CJ\\Steinwart - 2002 - On the influence of the kernel on the consistency .pdf:application/pdf},
}

@inproceedings{pedrosa_design_2017,
	address = {Kos, Greece},
	title = {A design methodology for the {Gaussian} {KLMS} algorithm},
	isbn = {978-0-9928626-7-1},
	url = {http://ieeexplore.ieee.org/document/8081688/},
	doi = {10.23919/EUSIPCO.2017.8081688},
	urldate = {2024-07-16},
	booktitle = {2017 25th {European} {Signal} {Processing} {Conference} ({EUSIPCO})},
	publisher = {IEEE},
	author = {Pedrosa, P. and Bermudez, J. C. M. and Richard, C.},
	month = aug,
	year = {2017},
	pages = {2634--2638},
	file = {Submitted Version:C\:\\Users\\Andre\\Zotero\\storage\\8RRM5WSH\\Pedrosa et al. - 2017 - A design methodology for the Gaussian KLMS algorit.pdf:application/pdf},
}

@book{manolakis_statistical_2005,
	address = {Boston London},
	series = {Artech {House} signal processing library},
	title = {Statistical and adaptive signal processing: spectral estimation, signal modeling, adaptive filtering, and array processing},
	isbn = {978-1-58053-610-3},
	shorttitle = {Statistical and adaptive signal processing},
	abstract = {This authoritative volume on statistical and adaptive signal processing offers you a unified, comprehensive and practical treatment of spectral estimation, signal modeling, adaptive filtering, and array processing. Packed with over 3,000 equations and more than 300 illustrations, this unique resource provides you with balanced coverage of implementation issues, applications, and theory, making it a smart choice for professional engineers and students alike},
	language = {eng},
	publisher = {Artech House},
	author = {Manolakis, Dimitris G. and Ingle, Vinay K. and Kogon, Stephen M.},
	year = {2005},
	annote = {"This is a reissue of a McGraw-Hill book"--Title page verso Includes bibliographical references (pages 769-785) and index},
}

@book{sayed_adaptive_2008,
	address = {Hoboken, N.J},
	title = {Adaptive filters},
	isbn = {978-0-470-25388-5},
	publisher = {Wiley-Interscience : IEEE Press},
	author = {Sayed, Ali H.},
	year = {2008},
	note = {OCLC: ocn191318239},
	keywords = {Adaptive filters},
}

@book{principe_kernel_2010,
	address = {Hoboken, N.J},
	series = {Adaptive and learning systems for signal processing, communication, and control},
	title = {Kernel adaptive filtering: a comprehensive introduction},
	isbn = {978-0-470-44753-6},
	shorttitle = {Kernel adaptive filtering},
	publisher = {John Wiley},
	author = {Príncipe, J. C. and Liu, Weifeng and Haykin, Simon S.},
	year = {2010},
	note = {OCLC: ocn368051917},
	keywords = {Kernel functions, Adaptive filters},
}

@book{haykin_adaptive_1996,
	address = {Upper Saddle River, NJ},
	edition = {3. ed},
	series = {Prentice {Hall} information and system sciences series},
	title = {Adaptive filter theory},
	isbn = {978-0-13-322760-4 978-0-13-397985-5},
	language = {eng},
	publisher = {Prentice Hall},
	author = {Haykin, Simon S.},
	year = {1996},
	annote = {Literaturverz. S. 941 - 977},
}

@article{taiho_koh_second-order_1985,
	title = {Second-order {Volterra} filtering and its application to nonlinear system identification},
	volume = {33},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {0096-3518},
	url = {http://ieeexplore.ieee.org/document/1164730/},
	doi = {10.1109/TASSP.1985.1164730},
	language = {en},
	number = {6},
	urldate = {2025-06-25},
	journal = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
	author = {{Taiho Koh} and Powers, E.},
	month = dec,
	year = {1985},
	pages = {1445--1455},
}

@article{scarpiniti_nonlinear_2013,
	title = {Nonlinear spline adaptive filtering},
	volume = {93},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {01651684},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0165168412003568},
	doi = {10.1016/j.sigpro.2012.09.021},
	language = {en},
	number = {4},
	urldate = {2025-06-25},
	journal = {Signal Processing},
	author = {Scarpiniti, Michele and Comminiello, Danilo and Parisi, Raffaele and Uncini, Aurelio},
	month = apr,
	year = {2013},
	pages = {772--783},
}

@book{paulsen_introduction_2016,
	address = {Cambridge},
	series = {Cambridge studies in advanced mathematics},
	title = {An introduction to the theory of reproducing kernel {Hilbert} spaces},
	isbn = {978-1-107-10409-9},
	language = {eng},
	number = {152},
	publisher = {Cambridge university press},
	author = {Paulsen, Vern I. and Raghupathi, Mrinal},
	year = {2016},
}

@book{riesz_functional_2009,
	address = {Mineola, NY},
	edition = {Nachdr.},
	series = {Dover books on mathematics},
	title = {Functional analysis},
	isbn = {978-0-486-66289-3},
	language = {eng},
	publisher = {Dover Publ},
	author = {Riesz, Frigyes and Szőkefalvi-Nagy, Béla and Boron, Leo F. and Riesz, Frigyes},
	year = {2009},
	annote = {Aus dem Franz. übers This Dover ed., first publ. in 1990, is an unabridged republ. of the work first publ. by Frederick Ungar Publ. Co., New York, in 1955},
	annote = {Bibliographies: p. 447 - 456, 491. - Includes index},
}

@article{liu_kernel_2008,
	title = {The {Kernel} {Least}-{Mean}-{Square} {Algorithm}},
	volume = {56},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {1053-587X},
	url = {http://ieeexplore.ieee.org/document/4410463/},
	doi = {10.1109/TSP.2007.907881},
	number = {2},
	urldate = {2025-06-25},
	journal = {IEEE Transactions on Signal Processing},
	author = {Liu, Weifeng and Pokharel, Puskal P. and Principe, Jose C.},
	month = feb,
	year = {2008},
	pages = {543--554},
}

@article{platt_resource-allocating_1991,
	title = {A {Resource}-{Allocating} {Network} for {Function} {Interpolation}},
	volume = {3},
	issn = {0899-7667, 1530-888X},
	url = {https://direct.mit.edu/neco/article/3/2/213-225/5577},
	doi = {10.1162/neco.1991.3.2.213},
	abstract = {We have created a network that allocates a new computational unit whenever an unusual pattern is presented to the network. This network forms compact representations, yet learns easily and rapidly. The network can be used at any time in the learning process and the learning patterns do not have to be repeated. The units in this network respond to only a local region of the space of input values.
            The network learns by allocating new units and adjusting the parameters of existing units. If the network performs poorly on a presented pattern, then a new unit is allocated that corrects the response to the presented pattern. If the network performs well on a presented pattern, then the network parameters are updated using standard LMS gradient descent.
            We have obtained good results with our resource-allocating network (RAN). For predicting the Mackey-Glass chaotic time series, RAN learns much faster than do those using backpropagation networks and uses a comparable number of synapses.},
	language = {en},
	number = {2},
	urldate = {2025-06-25},
	journal = {Neural Computation},
	author = {Platt, John},
	month = jun,
	year = {1991},
	pages = {213--225},
	file = {Submitted Version:C\:\\Users\\Andre\\Zotero\\storage\\UJKHK9XX\\Platt - 1991 - A Resource-Allocating Network for Function Interpo.pdf:application/pdf},
}

@article{engel_kernel_2004,
	title = {The {Kernel} {Recursive} {Least}-{Squares} {Algorithm}},
	volume = {52},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {1053-587X},
	url = {http://ieeexplore.ieee.org/document/1315946/},
	doi = {10.1109/TSP.2004.830985},
	language = {en},
	number = {8},
	urldate = {2025-06-25},
	journal = {IEEE Transactions on Signal Processing},
	author = {Engel, Y. and Mannor, S. and Meir, R.},
	month = aug,
	year = {2004},
	pages = {2275--2285},
}

@article{richard_online_2009,
	title = {Online {Prediction} of {Time} {Series} {Data} {With} {Kernels}},
	volume = {57},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {1053-587X, 1941-0476},
	url = {http://ieeexplore.ieee.org/document/4685707/},
	doi = {10.1109/TSP.2008.2009895},
	number = {3},
	urldate = {2025-06-25},
	journal = {IEEE Transactions on Signal Processing},
	author = {Richard, C. and Bermudez, J.C.M. and Honeine, P.},
	month = mar,
	year = {2009},
	pages = {1058--1067},
	file = {Submitted Version:C\:\\Users\\Andre\\Zotero\\storage\\8LD555TJ\\Richard et al. - 2009 - Online Prediction of Time Series Data With Kernels.pdf:application/pdf},
}

@article{badong_chen_quantized_2012,
	title = {Quantized {Kernel} {Least} {Mean} {Square} {Algorithm}},
	volume = {23},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {2162-237X, 2162-2388},
	url = {http://ieeexplore.ieee.org/document/6104217/},
	doi = {10.1109/TNNLS.2011.2178446},
	number = {1},
	urldate = {2025-06-25},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {{Badong Chen} and {Songlin Zhao} and {Pingping Zhu} and Principe, J. C.},
	month = jan,
	year = {2012},
	pages = {22--32},
}

@inproceedings{bouboulis_efficient_2016,
	address = {Palma de Mallorca, Spain},
	title = {Efficient {KLMS} and {KRLS} algorithms: {A} random fourier feature perspective},
	isbn = {978-1-4673-7803-1},
	shorttitle = {Efficient {KLMS} and {KRLS} algorithms},
	url = {http://ieeexplore.ieee.org/document/7551811/},
	doi = {10.1109/SSP.2016.7551811},
	urldate = {2025-06-25},
	booktitle = {2016 {IEEE} {Statistical} {Signal} {Processing} {Workshop} ({SSP})},
	publisher = {IEEE},
	author = {Bouboulis, Pantelis and Pougkakiotis, Spyridon and Theodoridis, S.},
	month = jun,
	year = {2016},
	pages = {1--5},
	file = {Submitted Version:C\:\\Users\\Andre\\Zotero\\storage\\QFCRRS3F\\Bouboulis et al. - 2016 - Efficient KLMS and KRLS algorithms A random fouri.pdf:application/pdf},
}

@article{bueno_gram-schmidt-based_2020,
	title = {Gram-{Schmidt}-{Based} {Sparsification} for {Kernel} {Dictionary}},
	volume = {27},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {1070-9908, 1558-2361},
	url = {https://ieeexplore.ieee.org/document/9124661/},
	doi = {10.1109/LSP.2020.3004022},
	urldate = {2025-06-25},
	journal = {IEEE Signal Processing Letters},
	author = {Bueno, Andre A. and Silva, Magno T. M.},
	year = {2020},
	pages = {1130--1134},
}

@book{buhmann_radial_2003,
	address = {Cambridge New York},
	series = {Cambridge monographs on applied and computational mathematics},
	title = {Radial basis functions: theory and implementations},
	isbn = {978-0-511-04020-7 978-0-511-54324-1},
	shorttitle = {Radial basis functions},
	language = {eng},
	number = {12},
	publisher = {Cambridge University Press},
	editor = {Buhmann, Martin},
	year = {2003},
	annote = {1. Introduction -- 1.1 Radial basis functions -- 1.2 Applications -- 1.3 Contents of the book -- 2. Summary of methods and applications -- 2.1 Invertibility of interpolation matrices -- 2.2 Convergence analysis -- 2.3 Interpolation and convergence -- 2.4 Applications to PDEs -- 3. General methods for approximation and interpolation -- 3.1 Polynomial schemes -- 3.2 Piecewise polynomials -- 3.3 General nonpolynomial methods -- 4. Radial basis function approximation on infinite grids -- 4.1 Existence of interpolants -- 4.2 Convergence analysis -- 4.3 Numerical properties of the interpolation linear system -- 4.4 Convergence with respect to parameters in the radial functions -- 5. Radial basis functions on scattered data -- 5.1 Nonsingularity of interpolation matrices -- 5.2 Convergence analysis -- 5.3 Norm estimates and condition numbers of interpolation matrices -- 6. Radial basis functions with compact support -- 6.1 Introduction -- 6.2 Wendland's functions -- 6.3 Another class of radial basis functions with compact support -- 6.4 Convergence -- 6.5 A unified class -- 7. Implementations -- 7.1 Introduction -- 7.2 The BFGP algorithm and the new Krylov method -- 7.3 The fast multipole algorithm -- 7.4 Preconditioning techniques -- 8. Least squares methods -- 8.1 Introduction to least squares -- 8.2 Approximation order results -- 8.3 Discrete least squares -- 8.4 Implementations -- 8.5 Neural network applications -- 9. Wavelet methods with radial basis functions -- 9.1 Introduction to wavelets and prewavelets -- 9.2 Basic definitions and constructions -- 9.3 Multiresolution analysis and refinement -- 9.4 Special constructions -- 10. Further results and open problems -- 10.1 Further results -- 10.2 Open problems -- Appendix: Some essentials on Fourier transforms In many areas of mathematics, science and engineering, from computer graphics to inverse methods to signal processing, it is necessary to estimate parameters, usually multidimensional, by approximation and interpolation. Radial basis functions are a powerful tool which work well in very general circumstances and so are becoming of widespread use as the limitations of other methods, such as least squares, polynomial interpolation or wavelet-based, become apparent. The author's aim is to give a thorough treatment from both the theoretical and practical implementation viewpoints. For example, he emphasises the many positive features of radial basis functions such as the unique solvability of the interpolation problem, the computation of interpolants, their smoothness and convergence and provides a careful classification of the radial basis functions into types that have different convergence. A comprehensive bibliography rounds off what will prove a very valuable work},
	annote = {Includes bibliographical references (p. 246-257) and index. - Description based on print version record},
}

@book{scholkopf_learning_2002,
	address = {Cambridge, Mass},
	series = {Adaptive computation and machine learning},
	title = {Learning with kernels: support vector machines, regularization, optimization, and beyond},
	isbn = {978-0-262-19475-4 978-0-262-25693-3 978-0-585-47759-6},
	shorttitle = {Learning with kernels},
	abstract = {In the 1990s, a new type of learning algorithm was developed, based on results from statistical learning theory: the Support Vector Machine (SVM). This gave rise to a new class of theoretically elegant learning machines that use a central concept of SVMs -- -kernels--for a number of learning tasks. Kernel machines provide a modular framework that can be adapted to different tasks and domains by the choice of the kernel function and the base algorithm. They are replacing neural networks in a variety of fields, including engineering, information retrieval, and bioinformatics. Learning with Kernels provides an introduction to SVMs and related kernel methods. Although the book begins with the basics, it also includes the latest research. It provides all of the concepts necessary to enable a reader equipped with some basic mathematical knowledge to enter the world of machine learning using theoretically well-founded yet easy-to-use kernel algorithms and to understand and apply the powerful algorithms that have been developed over the last few years},
	language = {eng},
	publisher = {MIT Press},
	author = {Schölkopf, Bernhard},
	collaborator = {Smola, Alexander J.},
	year = {2002},
}

@book{thompson_handbook_1999,
	address = {Boca Raton London New York [etc.]},
	title = {Handbook of grid generation},
	isbn = {978-0-8493-2687-5},
	language = {eng},
	publisher = {CRC Press},
	author = {Thompson, Joe F. and Soni, Bharat K. and Weatherill, Nigel P.},
	year = {1999},
}

@book{conway_sphere_1993,
	address = {New York, NY},
	edition = {Second Edition},
	series = {Grundlehren der mathematischen {Wissenschaften}, {A} {Series} of {Comprehensive} {Studies} in {Mathematics}},
	title = {Sphere {Packings}, {Lattices} and {Groups}},
	isbn = {978-1-4757-2249-9},
	abstract = {The second edition of this timely, definitive, and popular book continues to pursue the question: what is the most efficient way to pack a large number of equal spheres in n-dimensional Euclidean space? The authors also continue to examine related problems such as the kissing number problem, the covering problem, the quantizing problem, and the classification of lattices and quadratic forms. Like the first edition, the second edition describes the applications of these questions to other areas of mathematics and science such as number theory, coding theory, group theory, analog-to-digital conversion and data compression, n-dimensional crystallography, and dual theory and superstring theory in physics. Results as of 1992 have been added to the text, and the extensive bibliography - itself a contribution to the field - is supplemented with approximately 450 new entries},
	language = {eng},
	number = {290},
	publisher = {Springer},
	author = {Conway, John Horton and Sloane, N. J. A.},
	year = {1993},
	doi = {10.1007/978-1-4757-2249-9},
}

@book{meyer_matrix_2023,
	address = {Philadelphia, PA},
	edition = {Second edition},
	series = {Other titles in applied mathematics},
	title = {Matrix analysis and applied linear algebra: study and solutions guide},
	isbn = {978-1-61197-745-5 978-1-61197-743-1},
	shorttitle = {Matrix analysis and applied linear algebra},
	language = {eng},
	number = {189},
	publisher = {Siam, Society for Industrial and Applied Mathematics},
	author = {Meyer, Carl D.},
	year = {2023},
	file = {Table of Contents PDF:C\:\\Users\\Andre\\Zotero\\storage\\DAUEHYXW\\Meyer - 2023 - Matrix analysis and applied linear algebra study .pdf:application/pdf},
}

@book{horn_matrix_2017,
	address = {New York, NY},
	edition = {Second edition, corrected reprint},
	title = {Matrix analysis},
	isbn = {978-0-521-54823-6 978-0-521-83940-2},
	language = {eng},
	publisher = {Cambridge University Press},
	author = {Horn, Roger A. and Johnson, Charles R.},
	year = {2017},
	annote = {Literaturverzeichnis: Seite 571-574 Hier auch später erschienene, unveränderte Nachdrucke},
	file = {Table of Contents PDF:C\:\\Users\\Andre\\Zotero\\storage\\LTBUCMMD\\Horn and Johnson - 2017 - Matrix analysis.pdf:application/pdf},
}

@book{rudin_functional_2007,
	address = {Boston, Mass.},
	edition = {2. ed., [Nachdr.]},
	series = {International series in pure and applied mathematics},
	title = {Functional analysis},
	isbn = {978-0-07-054236-5},
	language = {eng},
	publisher = {McGraw-Hill},
	author = {Rudin, Walter},
	year = {2007},
	annote = {Literaturverz. S. 412 - 413 Hier auch später erschienene, unveränd. Nachdr},
	file = {Table of Contents PDF:C\:\\Users\\Andre\\Zotero\\storage\\6HQLPGA2\\Rudin - 2007 - Functional analysis.pdf:application/pdf},
}

@article{unser_sampling-50_2000,
	title = {Sampling-50 years after {Shannon}},
	volume = {88},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {0018-9219, 1558-2256},
	url = {http://ieeexplore.ieee.org/document/843002/},
	doi = {10.1109/5.843002},
	number = {4},
	urldate = {2025-06-25},
	journal = {Proceedings of the IEEE},
	author = {Unser, M.},
	month = apr,
	year = {2000},
	pages = {569--587},
	file = {Full Text:C\:\\Users\\Andre\\Zotero\\storage\\KU2G8THB\\Unser - 2000 - Sampling-50 years after Shannon.pdf:application/pdf},
}

@book{boor_box_1993,
	address = {New York, NY},
	series = {Applied {Mathematical} {Sciences}},
	title = {Box {Splines}},
	isbn = {978-1-4419-2834-4 978-1-4757-2244-4},
	abstract = {This book on box splines is the first book giving a complete development for any kind of multivariate spline. Box splines give rise to an intriguing and beautiful mathematical theory that is much richer and more intricate than the univariate case because of the complexity of smoothly joining polynomial pieces on polyhedral cells. The purpose of this book is to provide the basic facts about box splines in a cohesive way with simple, complete proofs, many illustrations, and with an up-to-date bibliography. It is not the book's intention to be encyclopedic about the subject, but rather to provide the fundamental knowledge necessary to familiarize graduate students and researchers in analysis, numerical analysis, and engineering with a subject that surely will have as many widespread applications as its univariate predecessor. This book will be used as a supplementary text for graduate courses. The book begins with chapters on box splines defined, linear algebra of box spline spaces, and quasi-interpolants and approximation power. It continues with cardinal interpolation and difference equations, approximation by cardinal splines and wavelets. The book concludes with discrete box splines and linear diophantine equations, and subdivision algorithms},
	language = {eng},
	number = {98},
	publisher = {Springer},
	author = {Boor, Carl and Höllig, Klaus and Riemenschneider, Sherman},
	year = {1993},
	doi = {10.1007/978-1-4757-2244-4},
}

@book{wendland_scattered_2005,
	address = {Cambridge, UK ; New York},
	series = {Cambridge monographs on applied and computational mathematics},
	title = {Scattered data approximation},
	isbn = {978-0-521-84335-5},
	number = {17},
	publisher = {Cambridge University Press},
	author = {Wendland, Holger},
	year = {2005},
	keywords = {Approximation theory, Multivariate analysis},
}

@article{aronszajn_theory_1950,
	title = {Theory of reproducing kernels},
	volume = {68},
	issn = {0002-9947, 1088-6850},
	url = {https://www.ams.org/tran/1950-068-03/S0002-9947-1950-0051437-7/},
	doi = {10.1090/S0002-9947-1950-0051437-7},
	language = {en},
	number = {3},
	urldate = {2025-06-25},
	journal = {Transactions of the American Mathematical Society},
	author = {Aronszajn, N.},
	year = {1950},
	pages = {337--404},
	file = {Full Text:C\:\\Users\\Andre\\Zotero\\storage\\EY8K7A3Y\\Aronszajn - 1950 - Theory of reproducing kernels.pdf:application/pdf},
}

@article{wiener_tauberian_1932,
	title = {Tauberian {Theorems}},
	volume = {33},
	issn = {0003486X},
	url = {https://www.jstor.org/stable/1968102?origin=crossref},
	doi = {10.2307/1968102},
	number = {1},
	urldate = {2025-06-25},
	journal = {The Annals of Mathematics},
	author = {Wiener, Norbert},
	month = jan,
	year = {1932},
	pages = {1},
}

@article{mayer_lowdins_2002,
	title = {On {Löwdin}'s method of symmetric orthogonalization*},
	volume = {90},
	copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
	issn = {0020-7608, 1097-461X},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/qua.981},
	doi = {10.1002/qua.981},
	abstract = {Abstract
            An elementary direct proof is given for the stationarity property of Löwdin's symmetric orthogonalization scheme. © 2002 Wiley Periodicals, Inc. Int J Quantum Chem, 2002},
	language = {en},
	number = {1},
	urldate = {2025-06-25},
	journal = {International Journal of Quantum Chemistry},
	author = {Mayer, I.},
	month = jan,
	year = {2002},
	pages = {63--65},
}

@article{carlson_orthogonalization_1957,
	title = {Orthogonalization {Procedures} and the {Localization} of {Wannier} {Functions}},
	volume = {105},
	copyright = {http://link.aps.org/licenses/aps-default-license},
	issn = {0031-899X},
	url = {https://link.aps.org/doi/10.1103/PhysRev.105.102},
	doi = {10.1103/PhysRev.105.102},
	language = {en},
	number = {1},
	urldate = {2025-06-25},
	journal = {Physical Review},
	author = {Carlson, B. C. and Keller, Joseph M.},
	month = jan,
	year = {1957},
	pages = {102--103},
}

@book{kay_modern_1988,
	address = {Englewood Cliffs, NJ},
	series = {Prentice-{Hall} signal processing series},
	title = {Modern spectral estimation: theory and application},
	isbn = {978-0-13-598582-3},
	shorttitle = {Modern spectral estimation},
	language = {eng},
	publisher = {Prentice Hall},
	author = {Kay, Steven M.},
	year = {1988},
}

@article{scargle_studies_1982,
	title = {Studies in astronomical time series analysis. {II} - {Statistical} aspects of spectral analysis of unevenly spaced data},
	volume = {263},
	issn = {0004-637X, 1538-4357},
	url = {http://adsabs.harvard.edu/doi/10.1086/160554},
	doi = {10.1086/160554},
	language = {en},
	urldate = {2025-06-25},
	journal = {The Astrophysical Journal},
	author = {Scargle, J. D.},
	month = dec,
	year = {1982},
	pages = {835},
}

@misc{seilmayer_multivariate_2020,
	title = {The {Multivariate} {Extension} of the {Lomb}-{Scargle} {Method}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2001.10200},
	doi = {10.48550/ARXIV.2001.10200},
	abstract = {The common methods of spectral analysis for multivariate (\$n\$-dimensional) time series, like discrete Frourier transform (FT) or Wavelet transform, are based on Fourier series to decompose discrete data into a set of trigonometric model components, e. g. amplitude and phase. Applied to discrete data with a finite range several limitations of (time discrete) FT can be observed which are caused by the orthogonality mismatch of the trigonometric basis functions on a finite interval. However, in the general situation of non-equidistant or fragmented sampling FT based methods will cause significant errors in the parameter estimation. Therefore, the classical Lomb-Scargle method (LSM), which is not based on Fourier series, was developed as a statistical tool for one dimensional data to circumvent the inconsistent and erroneous parameter estimation of FT. The present work deduces LSM for \$n\$-dimensional data sets by a redefinition of the shifting parameter \$τ\$, to maintain orthogonality of the trigonometric basis. An analytical derivation shows, that \$n\$-D LSM extents the traditional 1D case preserving all the statistical benefits, such as the improved noise rejection. Here, we derive the parameter confidence intervals for LSM and compare it with FT. Applications with ideal test data and experimental data will illustrate and support the proposed method.},
	urldate = {2025-06-25},
	publisher = {arXiv},
	author = {Seilmayer, Martin and Gonzalez, Ferran Garcia and Wondrak, Thomas},
	year = {2020},
	note = {Version Number: 3},
	keywords = {FOS: Computer and information sciences, FOS: Physical sciences, Instrumentation and Methods for Astrophysics (astro-ph.IM), Methodology (stat.ME)},
	annote = {Other
to be published},
}

@article{al-naffouri_transient_2003,
	title = {Transient analysis of data-normalized adaptive filters},
	volume = {51},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {1053-587X},
	url = {http://ieeexplore.ieee.org/document/1179756/},
	doi = {10.1109/TSP.2002.808106},
	language = {en},
	number = {3},
	urldate = {2025-06-25},
	journal = {IEEE Transactions on Signal Processing},
	author = {Al-Naffouri, T.Y. and Sayed, A.H.},
	month = mar,
	year = {2003},
	pages = {639--652},
}

@book{oppenheim_discrete-time_2010,
	address = {Upper Saddle River Munich},
	edition = {3. ed., internat. ed., [Nachdr.]},
	title = {Discrete-time signal processing},
	isbn = {978-0-13-206709-6},
	language = {eng},
	publisher = {Pearson Education},
	author = {Oppenheim, Alan V. and Schafer, Ronald W.},
	year = {2010},
	annote = {Literaturverz. S. 1106 - 1114},
	file = {Table of Contents PDF:C\:\\Users\\Andre\\Zotero\\storage\\97ASGG73\\Oppenheim and Schafer - 2010 - Discrete-time signal processing.pdf:application/pdf},
}
